# Ανίχνευση Συναισθημάτων σε Ηχητικά Δεδομένα

---

## 1. Σκοπός και Στόχοι

Η παρούσα εργασία ασχολείται με αναγνώριση συναισθήματος *(Speech Emotion Recognition)* βασισμένη σε ηχητικά δεδομένα και κλασικά μοντέλα μηχανικής μάθησης. Το κύριο dataset είναι το IEMOCAP *(Interactive Emotional Dyadic Motion Capture)*, ένα ευρέως χρησιμοποιούμενο corpus για έρευνα στη συναισθηματική ανάλυση ομιλίας.

**Στόχος:** Ταξινόμηση ομιλίας σε 4 κλάσεις συναισθήματος — *θυμός (angry)*, *χαρά (happy)*, *ουδέτερο συναίσθημα (neutral)*, *λύπη (sad)* — χρησιμοποιώντας pipeline προεπεξεργασίας, εξαγωγής χαρακτηριστικών και εκπαίδευσης/αξιολόγησης πολλαπλών ταξινομητών.

---

## 2. Τεχνολογίες και Εργαλεία

Το project είναι καθαρά **Python-based** και βασίζεται σε βιβλιοθήκες ML και ήχου:

| Κατηγορία | Τεχνολογία |
|-----------|------------|
| **ML / Ταξινόμηση** | scikit-learn, XGBoost |
| **Βελτιστοποίηση υπερπαραμέτρων** | Optuna (μέσω RandomizedSearchCV) |
| **Ήχος / Σήμα** | librosa, soundfile, pyAudioAnalysis |
| **Δεδομένα** | pandas, numpy |
| **Οπτικοποίηση** | matplotlib, seaborn |

Η βασική αρχιτεκτονική αποτελείται από python scripts (π.χ. `01_preprocess_data.py` → `08_one_shot_predict_eval.py`) τα οποία περιέχουν όλη τη λειτουργικότητα και χρησιμοποιούνται στα workflows - pipelines για την υλοποίηση τριών πειραμάτων (βλ. [Ενότητα 5](#5-δομή-pipeline-και-workflows)).

---

## 3. Δεδομένα

### 3.1 IEMOCAP

- **Πηγή:** IEMOCAP (metadata σε `iemocap_full_dataset.csv`, αρχεία ήχου οργανωμένα σε sessions).
- **Ετικέτες:** `Angry`, `Happy`, `Neutral`, `Sad`. Οι κατηγορίες Happy και Excited του αρχικού dataset συνενώθηκαν σε μία τελική κατηγορία `Happy`. Τα υπόλοιπα labels του dataset (fea, dis, fru, sur, oth, xxx) απορρίφθηκαν.
- **Μετά την προεπεξεργασία:**
  - **5.531 δείγματα** (από 10.039 metadata).
  - **272 χαρακτηριστικά** ανά δείγμα (68 βασικά × 4 στατιστικά: mean, min, max, std).

**Κατανομή κλάσεων:**

| Κλάση   | Πλήθος | Ποσοστό |
|---------|--------|--------|
| neutral | 1.708  | 30,9%  |
| happy   | 1.636  | 29,6%  |
| angry   | 1.103  | 19,9%  |
| sad     | 1.084  | 19,6%  |

**Εξαγωγή χαρακτηριστικών:** 

Για την εξαγωγή των χαρακτηριστικών χρησιμοποιήθηκε η βιβλιοθήκη pyAudioAnalysis με παράθυρο 50 ms και βήμα 25 ms. Η διαδικασία ξεκινά με την κατάτμηση του σήματος σε χρονικά παράθυρα (frames), στα οποία υπολογίζονται χαρακτηριστικά τόσο στο χρονικό πεδίο (π.χ. Zero Crossing Rate, ενέργεια) όσο και στο φασματικό μέσω του μετασχηματισμού Fourier (π.χ. spectral centroid, spread, entropy, flux, MFCCs και chroma). Επιπλέον, εξάγονται τα χαρακτηριστικα για την αποτύπωση του ρυθμού μεταβολής των παραπάνω μεγεθών. Τέλος, οι τιμές των χαρακτηριστικών συνοψίζονται ανά αρχείο ομιλίας μέσω στατιστικών δεικτών (μέση τιμή, ελάχιστο, μέγιστο και τυπική απόκλιση), καταλήγοντας σε ένα τελικό διάνυσμα 272 διαστάσεων ανά δείγμα.

### 3.2 CREMA-D

Στο project χρησιμοποιείται και ένα δεύτερο dataset, το CREMA-D για zero-shot αξιολόγηση. Συγκεκριμένα, αφού τα μοντέλα εκπαιδευτούν στο IEMOCAP αξιολογούνται στο CREMA-D, ώστε να ελεγχθεί η γενίκευση που επιτυγχάνουν.

Εφαρμόζεται η ίδια διαδικασία προεπεξεργασίας και εξαγωγής χαρακτηριστικών όπως στο IEMOCAP (pyAudioAnalysis, παράθυρο 50 ms, βήμα 25 ms, 68 βασικά χαρακτηριστικά × 4 στατιστικά → 272 διαστάσεων ανά δείγμα). Τα δεδομένα βρίσκονται στο φάκελο `cremad_zero_shot_dataset/` (αρχεία `cremad_features.csv`, `cremad_feature_report.txt`).

- **Μετά την προεπεξεργασία:** Απέμειναν 4.900 δείγματα (απορρίφθηκαν 2.542 από τα 7.442).
- **Ετικέτες:** Οι ίδιες 4 κλάσεις — `angry`, `happy`, `neutral`, `sad`.

**Κατανομή κλάσεων (CREMA-D):**

| Κλάση   | Πλήθος | Ποσοστό |
|---------|--------|--------|
| angry   | 1.271  | 25,9%  |
| happy   | 1.271  | 25,9%  |
| sad     | 1.271  | 25,9%  |
| neutral | 1.087  | 22,2%  |

---

## 4. Μετρικές Αξιολόγησης

Για την αξιολόγηση της απόδοσης των μοντέλων χρησιμοποιήθηκε ένα σύνολο μετρικών που καλύπτει τόσο προβλήματα ταξινόμησης όσο και παλινδρόμησης, παρέχοντας μια ολοκληρωμένη εικόνα της συμπεριφοράς των αλγορίθμων. Συγκεκριμένα, για την αξιολόγηση της ταξινόμησης συναισθημάτων εφαρμόστηκαν οι μετρικές Accuracy, Precision (weighted), Recall (weighted) και F1-score (weighted), οι οποίες λαμβάνουν υπόψη την ανισορροπία μεταξύ των κλάσεων και αποτυπώνουν την ικανότητα του κάθε μοντέλου να διακρίνει αποτελεσματικά τα μοτίβα συναισθήματος που κωδικοποιούνται στα εξαγόμενα χαρακτηριστικά. Παράλληλα, χρησιμοποιήθηκαν οι μετρικές R², MSE, RMSE, MAE και MAPE για την ποσοτική αποτίμηση της ακρίβειας των προβλέψεων σε συνεχή κλίμακα, επιτρέποντας την ανάλυση του μεγέθους και της διασποράς των σφαλμάτων. Ο συνδυασμός των παραπάνω μετρικών εξασφαλίζει μια αξιόπιστη και σφαιρική αξιολόγηση της συνολικής απόδοσης του προτεινόμενου συστήματος.

---

## 5. Δομή Pipeline και Workflows

Η αρχιτεκτονική του project είναι modular: κάθε ροή εργασίας *(workflow)* αξιοποιεί τα κοινά σενάρια επεξεργασίας από τον φάκελο scripts/, ενώ τα αποτελέσματα εξάγονται σε ξεχωριστούς φάκελους (workflows/<workflow_name>/), διασφαλίζοντας την οργάνωση των δεδομένων.

### 5.1 Workflow **IEMOCAP 80-20** (`workflows/iemocap_80_20/`)

1. **Preprocess** — IEMOCAP → εξαγωγή χαρακτηριστικών → `iemocap_features.csv`.
2. **Split** — stratified διαχωρισμός 80-20 (Train 4.424, Test 1.107), κανονικοποίηση *(StandardScaler)* στο train και εφαρμογή στο test· αποθήκευση `scaler.pkl`.
3. **Train** — Εκπαίδευση 7 ταξινομητών (RF, XGB, SVM, KNN, DTR, Logistic, NB).
4. **Evaluate** — Αξιολόγηση με τα ακόλουθα metrics: accuracy, F1, precision, recall, confusion matrix, learning curves.
5. **Hyperparameter tuning** — RandomizedSearchCV (weighted F1), αποθήκευση best params και μοντέλων.
6. **Τελικό Evaluation** — Αξιολόγηση με τα tuned μοντέλα.
7. **Zero-shot** —  Έλεγχος γενίκευσης του μοντέλου σε εξωτερικά datasets.

### 5.2 Workflow **IEMOCAP PCA** (`workflows/iemocap_pca/`)

1. Preprocess IEMOCAP.
2. Split 80-20 χωρίς κανονικοποίηση.
3. Εφαρμογή **PCA** στο train (threshold αθροιστικού variance 0,99), backup των παλιών train/test σε `*_old.csv`.
4. Train → Evaluate → Tuning → Evaluate.
5. **Zero-shot** με CREMA-D τα features του zero-shot περνούν από το ίδιο PCA/scaler.

**PCA:** 136 αρχικές διαστάσεις, 135 τελικά components για 99,26% cumulative explained variance.

### 5.3 Workflow IEMOCAP LOSO (`workflows/iemocap_loso/`)

- **Leave-One-Subject-Out:** Διαμερισμός ανά fold κάθε fold αφήνει έξω ένα session για test.
- **5 folds** (fold_0 … fold_4)· ανά fold: train → tuning → evaluate → zero-shot (CREMA-D).
- Τα αποτελέσματα αθροίζονται στο `results/loso_summary.txt`.

---

## 6. Αναλυτική Παρουσίαση Αποτελεσμάτων

Στην ενότητα αυτή παρατίθενται τα αναλυτικά αποτελέσματα για κάθε Workflow.

### 6.1 Αποτελέσματα Workflow 1: IEMOCAP 80-20

Στο βασικό σενάριο, χρησιμοποιούμε όλα τα χαρακτηριστικά (272) και stratified διαχωρισμό. Εδώ τα μοντέλα έχουν την καλύτερη δυνατή "εικόνα" των δεδομένων.

**Συγκεντρωτικός Πίνακας (Test Set):**

| Μοντέλο | Accuracy | F1 (Weighted) | Precision (Weighted) | Recall (Weighted) |
| :--- | :---: | :---: | :---: | :---: |
| XGBoost (XGB) | **0.6224** | **0.6221** | **0.6280** | **0.6224** |
| SVM | **0.6125** | **0.6125** | **0.6155** | **0.6125** |
| Logistic Regression | 0.5990 | 0.5980 | 0.5990 | 0.5990 |
| Random Forest (RF) | 0.5881 | 0.5878 | 0.5949 | 0.5881 |
| K-Nearest Neighbors (KNN)| 0.5570 | 0.5520 | 0.5590 | 0.5570 |
| Naive Bayes (NB) | 0.4920 | 0.4780 | 0.4950 | 0.4920 |
| Decision Tree (DTR) | 0.4690 | 0.4680 | 0.4690 | 0.4690 |

![F1 Score Weighted](workflows/iemocap_80_20/results/Metrics_graphs/F1_score_weighted.png)

**Ανάλυση ανά Μοντέλο:**
*   **XGBoost:** Πέτυχε την κορυφαία επίδοση σε όλες τις μετρικές. Η ικανότητά του να χτίζει διαδοχικά δέντρα διορθώνοντας τα λάθη των προηγούμενων, το καθιστά εξαιρετικά αποτελεσματικό στο να διακρίνει τις λεπτές διαφορές μεταξύ των συναισθημάτων.
*   **SVM:** Σχεδόν ισάξια απόδοση με το XGBoost. Το RBF kernel κατάφερε να διαχωρίσει τις κλάσεις στον χώρο των 272 διαστάσεων.
*   **Logistic Regression:** Βρίσκεται στην η 3η θέση, αποδεικνύοντας ότι υπάρχει γραμμική συνιστώσα στα χαρακτηριστικά που μπορεί να αξιοποιηθεί.
*   **Random Forest:** Αν και ισχυρό, βρίσκεται στην 4η θέση λόγω υπερβολικής προσαρμογής (overfitting).
*   **KNN:** Μέτρια επίδοση. Η ευκλείδεια απόσταση σε τόσες πολλές διαστάσεις χάνει το νόημά της (curse of dimensionality), ρίχνοντας την ακρίβεια.
*   **Naive Bayes & DTR:** Σημαντικά χαμηλότερες επιδόσεις. Το DTR είναι ασταθές και επιρρεπές σε θόρυβο, ενώ ο NB κάνει πολύ απλοϊκές υποθέσεις για τα δεδομένα.

![Confusion Matrix XGB](workflows/iemocap_80_20/results/xgb/confusion_matrix.png)

---

### 6.2 Αποτελέσματα Workflow 2: IEMOCAP PCA

Εδώ εξετάζουμε την επίδραση της μείωσης διαστάσεων (135 components, 99% variance).

**Συγκεντρωτικός Πίνακας:**

| Μοντέλο | Accuracy | F1 (Weighted) | Precision (Weighted) | Recall (Weighted) |
| :--- | :---: | :---: | :---: | :---: |
| Logistic Regression | **0.5810** | **0.5810** | **0.5820** | **0.5810** |
| SVM | 0.5600 | 0.5610 | 0.5620 | 0.5600 |
| XGBoost (XGB) | 0.5140 | 0.5150 | 0.5250 | 0.5140 |
| Random Forest (RF) | 0.4700 | 0.4630 | 0.5160 | 0.4700 |
| K-Nearest Neighbors (KNN)| 0.4070 | 0.3910 | 0.4290 | 0.4070 |
| Decision Tree (DTR) | 0.3590 | 0.3580 | 0.3580 | 0.3590 |
| Naive Bayes (NB) | 0.3520 | 0.3350 | 0.3890 | 0.3520 |

**Ανάλυση ανά Μοντέλο:**
*   **Logistic & SVM:** Τα γραμμικά μοντέλα έδειξαν μεγάλη ανθεκτικότητα. Το PCA συμπύκνωσε την πληροφορία με τρόπο που τα βοήθησε να κρατήσουν ψηλά την απόδοση (~58%), απομακρύνοντας τον θόρυβο.
*   **XGBoost & RF:** Κατέγραψαν μεγάλη πτώση (~10% για το XGB). Τα δέντρα αποφάσεων δυσκολεύονται να λειτουργήσουν πάνω σε Principal Components, καθώς αυτά είναι γραμμικοί συνδυασμοί των αρχικών χαρακτηριστικών και δεν έχουν φυσική σημασία (π.χ. "ένταση φωνής") πάνω στην οποία "κόβουν" τα δέντρα.
*   **Υπόλοιπα:** DTR, NB και KNN είχαν πολύ κακή απόδοση, καθιστώντας το PCA απαγορευτικό για τη χρήση τους σε αυτό το πρόβλημα.

---

### 6.3 Αποτελέσματα Workflow 3: IEMOCAP LOSO

 Μοντέλα δοκιμάζονται σε άγνωστους ομιλητές (Cross-Validation).

**Συγκεντρωτικός Πίνακας (Mean ± Std):**

| Μοντέλο | Accuracy | F1 (Weighted) | Precision (Weighted) | Recall (Weighted) |
| :--- | :---: | :---: | :---: | :---: |
| SVM | **0.5638** | **0.5634** | **0.5801** | **0.5638** |
| XGBoost (XGB) | 0.5626 | 0.5613 | 0.5722 | 0.5626 |
| Random Forest (RF) | 0.5455 | 0.5447 | 0.5653 | 0.5455 |
| Logistic Regression | 0.5358 | 0.5320 | 0.5420 | 0.5358 |
| K-Nearest Neighbors (KNN)| 0.5153 | 0.5105 | 0.5298 | 0.5153 |
| Naive Bayes (NB) | 0.4795 | 0.4637 | 0.4810 | 0.4795 |
| Decision Tree (DTR) | 0.4367 | 0.4367 | 0.4457 | 0.4367 |

**Ανάλυση ανά Μοντέλο:**
*   **SVM & XGBoost:** Κατέχουν την πρώτη θέση (~56%). Το SVM δείχνει μια ελαφριά υπεροχή στο Precision, ενώ το XGBoost είναι αρκετά σταθερό. Η πτώση σε σχέση με το 80-20 είναι μικρή (~6%), αποδεικνύοντας ότι έχουν μάθει γενικεύσιμα χαρακτηριστικά.
*   **Random Forest:** Πλησιάζει αρκτά τους πρώτους. Τα ensembles (RF, XGB) είναι γενικά πιο ανθεκτικά σε αλλαγές ομιλητών.
*   **Logistic Regression:** Έπεσε στην 4η θέση. Φαίνεται πως οι διαφορές μεταξύ ομιλητών δεν είναι γραμμικά διαχωρίσιμες όσο εύκολα ήταν τα δείγματα του ίδιου ομιλητή.
*   **KNN, NB, DTR:** Παραμένουν στις τελευταίες θέσεις, με το DTR να είναι το πιο ακατάλληλο για speaker-independent εφαρμογές.

---

## 7. Γενίκευση σε νέο dataset (Zero-Shot σε CREMA-D)

Ο τελικός έλεγχος αξιολογεί την ικανότητα των μοντέλων να λειτουργούν σε ένα άγνωστα dataset.

![Zero Shot Heatmap](workflows/iemocap_80_20/results/Metrics_graphs/Zero_shot_heatmap.png)

*   **Naive Bayes (54.3%):** Ενώ ήταν από τους χειρότερους στο IEMOCAP, στο CREMA-D είχε τις καλύτερες επιδόσεις. Η απλότητά του λειτούργησε ως πλεονέκτημα, αποφεύγοντας το overfitting στις ιδιαιτερότητες του IEMOCAP.
*   **XGBoost (52.2%):** Κράτησε καλή απόδοση, αλλά υπέφερε από το domain shift.
*   **SVM (50.8%):** Έπεσε σημαντικά, δείχνοντας ότι τα "όρια" που έμαθε στο IEMOCAP δεν μεταφράζονται τέλεια στο CREMA-D.

## 8. Συμπεράσματα

1.  **Καλύτερο Μοντέλο Γενικής Χρήσης:** Το **XGBoost** είναι η πιο ασφαλής επιλογή. Κερδίζει στο 80-20, ισοβαθμεί στο LOSO και είναι 2ο στο Zero-Shot.
2.  **Ρόλος της PCA:** Βοηθά μόνο τα Logistic Regression και SVM. Καταστρέφει την απόδοση των δενδρικών μοντέλων.
3.  **Γενίκευση:** Για εφαρμογές σε εντελώς νέα περιβάλλοντα (zero-shot), απαιτείται ιδιαίτερη προσοχή, καθώς ακόμη και απλά μοντέλα (π.χ. Naive Bayes) ενδέχεται να υπερέχουν έναντι πιο πολύπλοκων, γεγονός που καταδεικνύει πιθανά προβλήματα υπερπροσαρμογής.

---